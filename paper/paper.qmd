---
title: "My title"
subtitle: "My subtitle if needed"
author: 
  - Mandy He
  - Wendy Yuan
thanks: "Code and data are available at: https://github.com/MandyHe7/US-Election.git."
date: November 5, 2024
date-format: long
abstract: "First sentence. Second sentence. Third sentence. Fourth sentence."
format: pdf
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(dplyr)
library(readr)
library(ggplot2)
library(janitor)
library(lubridate)
library(broom)
library(modelsummary)
library(rstanarm)
library(splines)

polling_data <- read_csv(here::here("data/02-analysis_data/analysis_data.csv"))
```


# Introduction

Overview paragraph

Estimand paragraph

Results paragraph

Why it matters paragraph

Telegraphing paragraph: The remainder of this paper is structured as follows. @sec-data....

# Data {#sec-data}

## Overview

We use the statistical programming language R [@citeR].... Our data [@shelter].... Following @tellingstories, we consider...

Overview text

## Measurement
	
Some paragraphs about how we go from a phenomena in the world to an entry in the dataset.

## Outcome variables



## Predictor variables



# Model



```{r}
#### Plot data ####
base_plot <- ggplot(polling_data, aes(x = end_date, y = pct, color = answer)) +
  geom_point() +  # Add points to the plot
  theme_classic() +
  labs(y = "Percent", x = "Date", color = "Candidate") +  # Add a label for the legend
  scale_color_manual(values = c("Biden" = "blue", "Harris" = "orange"))  # Customize colors

# Plots poll estimates and overall smoothing
base_plot +
  geom_point() +
  geom_smooth()

```



```{r}
# Facet by pollster
base_plot +
  geom_point() +
  geom_smooth() +
  facet_wrap(vars(pollster))
```



```{r}
# Facet by state
base_plot +
  geom_point() +
  geom_smooth() +
  facet_wrap(vars(state))
```



# Results

Our results are summarized in @tbl-modelresults.

```{r}
#### Bayesian modeling ####
# Change 'pollster' and 'state' to factor variables
polling_data <- polling_data |>
  mutate(
    pollster = factor(pollster),
    state = factor(state)
  )

# Check if 'num_DEM' and 'sample_size' exist; if not, create them (adjust based on actual column names)
# Assuming 'pct_DEM' is the percentage of Democrat votes (adjust if necessary)
if (!("num_DEM" %in% colnames(polling_data))) {
  polling_data <- polling_data |> mutate(num_DEM = round(pct_DEM * sample_size / 100))
}

# Model 1
model_formula_1 <- cbind(num_DEM, sample_size - num_DEM) ~ (1 | pollster)

# Specify priors
priors <- normal(0, 2.5, autoscale = TRUE)

# Fit the models
bayesian_model_1 <- stan_glmer(
  formula = model_formula_1,
  data = polling_data,
  family = binomial(link = "logit"),
  prior = priors,
  prior_intercept = priors,
  seed = 123,
  cores = 1,
  adapt_delta = 0.99  # Increase adapt_delta to avoid divergent transitions
)

# Posterior predictive checks
pp_check(bayesian_model_1)

#### Bayesian models and splines ####
# Change date to be number of days since she declared - it's a counter not a date
polling_data <- polling_data |>
  mutate(
    end_date_num = as.numeric(end_date - min(end_date))
  )

# Fit Bayesian model with spline and pollster as fixed effect
spline_model <- stan_glm(
  pct ~ ns(end_date, df = 5) + pollster,  # Change df for the number of "bits"
  data = polling_data,
  family = gaussian(),
  prior = normal(0, 5),
  prior_intercept = normal(50, 10),
  seed = 1234,
  iter = 2000,
  chains = 4,
  refresh = 0
)

# Posterior predictive checks
pp_check(spline_model)

# Predict and plot
new_data <- data.frame(
  end_date = seq(
    min(polling_data$end_date),
    max(polling_data$end_date),
    length.out = 100
  ),
  pollster = factor("YouGov", levels = levels(polling_data$pollster))
)

# Predict posterior draws
posterior_preds <- posterior_predict(spline_model, newdata = new_data)

# Summarize predictions
pred_summary <- new_data |>
  mutate(
    pred_mean = colMeans(posterior_preds),
    pred_lower = apply(posterior_preds, 2, quantile, probs = 0.025),
    pred_upper = apply(posterior_preds, 2, quantile, probs = 0.975)
  )

# Plot the spline fit
ggplot(polling_data, aes(x = end_date, y = pct, color = pollster)) +
  geom_point() +
  geom_line(
    data = pred_summary,
    aes(x = end_date, y = pred_mean),
    color = "blue",
    inherit.aes = FALSE
  ) +
  geom_ribbon(
    data = pred_summary,
    aes(x = end_date, ymin = pred_lower, ymax = pred_upper),
    alpha = 0.2,
    inherit.aes = FALSE
  ) +
  labs(
    x = "Days since earliest poll",
    y = "Percentage",
    title = "Poll Percentage over Time with Spline Fit"
  ) +
  theme_minimal()
```

```{r}
#### Bayesian modeling ####
# Change 'pollster' and 'state' to factor variables
polling_data_2 <- polling_data |>
  mutate(
    pollster = factor(pollster),
    state = factor(state)  # State as a factor variable
  )

# Check if 'num_DEM' and 'sample_size' exist; if not, create them (adjust based on actual column names)
# Assuming 'pct_DEM' is the percentage of Democrat votes (adjust if necessary)
if (!("num_DEM" %in% colnames(polling_data))) {
  polling_data_2 <- polling_data_2 |> mutate(num_DEM = round(pct_DEM * sample_size / 100))
}

# Model 1: Random effect for state instead of pollster
model_formula_2 <- cbind(num_DEM, sample_size - num_DEM) ~ (1 | state)

# Specify priors
priors <- normal(0, 2.5, autoscale = TRUE)

# Fit the model with random effect for state
bayesian_model_2 <- stan_glmer(
  formula = model_formula_1,
  data = polling_data,
  family = binomial(link = "logit"),
  prior = priors,
  prior_intercept = priors,
  seed = 123,
  cores = 1,
  adapt_delta = 0.99  # Increase adapt_delta to avoid divergent transitions
)

# Posterior predictive checks
pp_check(bayesian_model_2)

#### Bayesian models and splines ####
# Change date to be number of days since she declared - it's a counter not a date
polling_data_2 <- polling_data_2 |>
  mutate(
    end_date_num = as.numeric(end_date - min(end_date))
  )

# Fit Bayesian model with spline and random effect for state
spline_model_2 <- stan_glm(
  pct ~ ns(end_date, df = 5) + state,  # State as random effect
  data = polling_data_2,
  family = gaussian(),
  prior = normal(0, 5),
  prior_intercept = normal(50, 10),
  seed = 1234,
  iter = 2000,
  chains = 4,
  refresh = 0
)

# Posterior predictive checks
pp_check(spline_model_2)

# Predict and plot
new_data_2 <- data.frame(
  end_date = seq(
    min(polling_data$end_date),
    max(polling_data$end_date),
    length.out = 100
  ),
  state = factor("California", levels = levels(polling_data$state))  # Example state
)

# Summarize predictions
pred_summary_2 <- new_data_2 |>
  mutate(
    pred_mean = colMeans(posterior_preds),
    pred_lower = apply(posterior_preds, 2, quantile, probs = 0.025),
    pred_upper = apply(posterior_preds, 2, quantile, probs = 0.975)
  )

# Plot the spline fit
ggplot(polling_data_2, aes(x = end_date, y = pct, color = state)) +
  geom_point() +
  geom_line(
    data = pred_summary_2,
    aes(x = end_date, y = pred_mean),
    color = "blue",
    inherit.aes = FALSE
  ) +
  geom_ribbon(
    data = pred_summary_2,
    aes(x = end_date, ymin = pred_lower, ymax = pred_upper),
    alpha = 0.2,
    inherit.aes = FALSE
  ) +
  labs(
    x = "Days since earliest poll",
    y = "Percentage",
    title = "Poll Percentage over Time with Spline Fit"
  ) +
  theme_minimal()
```

# Discussion

## First discussion point {#sec-first-point}

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this. 

## Second discussion point

Please don't use these as sub-heading labels - change them to be what your point actually is.

## Third discussion point



## Weaknesses and next steps

Weaknesses and next steps should also be included.

\newpage

\appendix

# Appendix {-}

# Appendix A: YouGov Pollster Methodology and Evaluation

1. Overview of YouGov
YouGov is a widely recognized international polling firm known for its political forecasting, especially through its "poll-of-polls" methodology, which aggregates results from numerous individual surveys. YouGov primarily utilizes online panel polling, offering timely and cost-effective results, especially for U.S. presidential elections. Below is a detailed exploration of YouGov's polling methodology.

2. Population, Frame, and Sample
Population: YouGov’s target population consists of U.S. likely voters, defined by their eligibility and likelihood to vote, assessed through past voting behavior, voter registration, and expressed intent.
Frame: The sampling frame is YouGov’s online panel, which includes millions of U.S. residents recruited through various methods. The panel is stratified and weighted to represent key demographics such as age, gender, race, education, and region.
Sample: YouGov uses non-probability sampling from its panel, adjusting for biases using sophisticated weighting to reflect the U.S. electorate's composition.

3. Sample Recruitment
YouGov recruits panelists through:
Targeted online ads: Ads across websites and social media attract diverse participants.
Affiliate marketing: Collaborations with other websites help reach a broad audience.
Incentives: Respondents earn points for surveys, increasing participation and retention.
However, because respondents voluntarily join the panel, there is potential for self-selection bias, as certain demographics may be more likely to participate.

4. Sampling Approach and Trade-offs
YouGov applies stratified sampling, setting quotas for demographics such as age, gender, race, education, and region. After data collection, post-stratification weighting adjusts for imbalances between the sample and the population.

Advantages:
Cost-effectiveness: Online panels are cheaper than traditional phone surveys.
Speed: Surveys are completed quickly online.
Targeting: Specific groups, such as likely voters, can be efficiently targeted.

Disadvantages:
Non-probability sample: Not all individuals have an equal chance of being selected, risking bias.
Internet access bias: Those without internet access may be underrepresented, skewing results, particularly for older or lower-income demographics.

5. Handling Non-response
To combat non-response, YouGov:
Incentivizes participation with rewards to increase survey completion.
Sends follow-ups for longer surveys, reminding respondents to complete them.
Applies weighting to adjust for differential non-response (e.g., giving more weight to younger voters if they are underrepresented).
Despite these efforts, some non-response bias may persist, as those opting out may differ systematically from respondents (e.g., lower political engagement).

6. Questionnaire Design: Strengths and Weaknesses
Strengths:
Clarity: Questions are designed for consistency in interpretation.
Pre-testing: Surveys are often tested with smaller groups to refine clarity and accuracy.
Flexibility: Questions are adapted to political events, maintaining relevance.

Weaknesses:
Limited depth: Online surveys favor simpler, multiple-choice questions, limiting nuanced responses.
Response fatigue: Frequent survey participation may cause rushed or less thoughtful responses.
Exclusion of offline participants: Individuals without internet access are excluded, impacting representativeness, particularly in underserved demographics.

7. Conclusion
YouGov’s online panel approach offers cost efficiency, speed, and adaptability, making it suitable for political forecasting. While its methodology effectively mitigates some biases through stratification and weighting, limitations like non-response bias, self-selection, and internet access gaps must be acknowledged. Despite these challenges, YouGov remains a leading firm in modern political forecasting.

# Appendix B: Idealized Methodology and Survey
1. Overview
With a $100K budget, the objective of this survey is to forecast the outcome of the upcoming U.S. presidential election using a robust sampling strategy, respondent recruitment process, and careful poll aggregation techniques. This methodology is designed to minimize bias and ensure a representative sample that accurately reflects the voting population.

2. Sampling Approach
The goal of the survey is to represent the U.S. electorate. To achieve this, the sampling strategy should include a multi-stage stratified random sampling approach. The following demographic groups should be stratified to ensure diversity:
Age: Ensure a balanced representation across different age groups (e.g., 18-29, 30-44, 45-64, 65+).
Gender: Include a balanced proportion of male and female respondents, and allow space for non-binary respondents.
Race/Ethnicity: Ensure representation of major racial and ethnic groups, including White, Black, Hispanic/Latino, Asian, and other minorities.
Education: Include respondents with various educational backgrounds (no high school, high school graduate, college graduate, post-graduate education).
Region: Sample respondents from different geographic regions (Northeast, Midwest, South, West) to capture regional variations in voting behavior.
Sample Size
Given the budget constraints and the need for statistical reliability, the survey would target a sample size of 5,000 respondents, which allows for meaningful subgroup analysis while keeping costs manageable. This should provide a margin of error around ±1.5% at a 95% confidence level.

3. Recruitment of Respondents
To recruit a diverse and representative sample, the following methods will be used:
Online recruitment via targeted ads: Similar to YouGov, targeted ads on social media platforms (e.g., Facebook, Instagram, YouTube) and websites can be used to attract a broad range of respondents. Ads will be tailored to reach different demographic groups based on age, region, and other factors.
Email outreach to existing voter databases: Leveraging voter registration lists and databases (where legally permissible) will allow for targeted invitations to participate in the survey.
Incentives: Offering incentives, such as entry into a lottery or digital rewards, will increase the participation rate and reduce non-response bias.
Given the budget, $80,000 will be allocated for recruitment efforts and respondent compensation, including targeted online ads and incentives for participants.

4. Data Validation
To ensure the data's accuracy and reduce the risk of fraudulent responses or duplicate submissions, the following measures will be implemented:
Captcha verification: This will prevent bots from filling out the survey.
Email and phone verification: Respondents will be required to verify their email or phone number to ensure that each respondent is unique.
Cross-verification with voter rolls: For respondents who voluntarily provide voter registration details, cross-checking with public voter rolls can validate their voting eligibility.
Time tracking and completion rate monitoring: To detect inattentive or rushed responses, the time spent on each question will be tracked, and surveys completed unusually quickly will be flagged for further review.

5. Poll Aggregation
To provide a more robust forecast, this survey will be integrated into a broader poll-of-polls approach, aggregating data from multiple sources, including:
Public polling data: In addition to this survey, data from other reputable pollsters (like YouGov, Ipsos, etc.) will be aggregated.
Weighting and adjusting: Each poll's results will be weighted based on its sample size, methodological rigor, and recency. Larger, more recent, and methodologically sound polls will have a greater influence on the final aggregated forecast.
Adjustments for known biases: If a particular demographic is underrepresented (e.g., younger voters, rural voters), post-stratification weighting will be applied to ensure the aggregate data reflects the overall voting population.

6. Budget Breakdown
Recruitment (online ads and outreach): $60,000
Incentives for respondents: $20,000
Survey development and data validation: $10,000
Poll aggregation and analysis tools: $10,000

7. Survey Implementation
To demonstrate the methodology, a Google Forms survey will be developed and deployed. The survey will be structured as follows:
Introduction: A brief explanation of the survey’s purpose, ensuring that respondents understand its relevance and importance.
Demographic questions: These questions will collect essential data on the respondents’ age, gender, race/ethnicity, education, and region.
Political questions: The core section will ask about voting intent, candidate preference, party affiliation, and important political issues. These questions will be designed to minimize bias and allow for nuanced responses (e.g., Likert scales, multiple-choice options).
Verification and consent: Respondents will be asked to verify their information and give consent for data use.
A link to the Google Forms survey will be included in the appendix, alongside a downloadable copy of the survey questions for transparency.

8. Survey Design Considerations
Question clarity and neutrality: The questions will be carefully worded to avoid leading responses or introducing bias.
Ordering of questions: Demographic questions will be asked first to set a neutral tone before moving into political questions.
Pilot testing: Before full deployment, the survey will be tested on a small sample to ensure clarity and to refine any confusing questions.

Form link: https://forms.gle/epk9ptyVxZpVRVLq9

\newpage

# References
